{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_calls = pd.read_csv(\"../datasets/CatakPreprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trojan'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malware_calls.iloc[0]['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ldrloaddll ldrgetprocedureaddress regopenkeyex...</td>\n",
       "      <td>Trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>getsystemtimeasfiletime ntallocatevirtualmemor...</td>\n",
       "      <td>Trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ldrgetdllhandle ldrgetprocedureaddress getsyst...</td>\n",
       "      <td>Backdoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ldrloaddll ldrgetprocedureaddress regopenkeyex...</td>\n",
       "      <td>Backdoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ldrloaddll ldrgetprocedureaddress wsastartup n...</td>\n",
       "      <td>Trojan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 api     class\n",
       "0  ldrloaddll ldrgetprocedureaddress regopenkeyex...    Trojan\n",
       "1  getsystemtimeasfiletime ntallocatevirtualmemor...    Trojan\n",
       "2  ldrgetdllhandle ldrgetprocedureaddress getsyst...  Backdoor\n",
       "3  ldrloaddll ldrgetprocedureaddress regopenkeyex...  Backdoor\n",
       "4  ldrloaddll ldrgetprocedureaddress wsastartup n...    Trojan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malware_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Trojan        1001\n",
       "Backdoor      1001\n",
       "Downloader    1001\n",
       "Worms         1001\n",
       "Virus         1001\n",
       "Dropper        891\n",
       "Spyware        832\n",
       "Adware         379\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malware_calls['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9467, 0.8592, 0.8592, 0.8746, 0.8829, 0.8592, 0.8592, 0.8592],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(malware_calls[\"class\"].value_counts())\n",
    "class_weights = (1 - (malware_calls['class'].value_counts().sort_index() / len(malware_calls))).values\n",
    "class_weights = torch.from_numpy(class_weights).float().to(\"cuda\")\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT2IDX = {\n",
    "    'Virus': 0,\n",
    "    'Trojan': 1,\n",
    "    'Worms': 2,\n",
    "    'Downloader': 3,\n",
    "    'Backdoor': 4,\n",
    "    'Dropper': 5,\n",
    "    'Spyware': 6,\n",
    "    'Adware': 7,\n",
    "}\n",
    "\n",
    "IDX2CAT = {\n",
    "    0:'Virus',\n",
    "    1:'Trojan',\n",
    "    2:'Worms',\n",
    "    3:'Downloader',\n",
    "    4:'Backdoor',\n",
    "    5:'Dropper',\n",
    "    6:'Spyware',\n",
    "    7:'Adware',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa4fcc35c004cc4889925281160eecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LlaMa 2 7B Model Checkpoint from Hugging Face (need to be logged in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f5e4318f7f453ba9af3b3aa825353d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes, label2id=CAT2IDX, id2label=IDX2CAT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(malware_calls.api, malware_calls['class'],\n",
    "test_size=0.2, random_state=75, stratify = malware_calls['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['class', 'api'],\n",
       "        num_rows: 5685\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['class', 'api'],\n",
       "        num_rows: 1422\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import datasets\n",
    "\n",
    "train = Dataset.from_pandas(pd.concat([Y_train, X_train], axis=1)).remove_columns('__index_level_0__')\n",
    "validation = Dataset.from_pandas(pd.concat([Y_test, X_test], axis=1)).remove_columns('__index_level_0__')\n",
    "\n",
    "dataset = datasets.DatasetDict({\"train\": train, \"validation\": validation})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Create Tokenized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the tokenized dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['class', 'api', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5685\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['class', 'api', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1422\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    #extract text\n",
    "    text = examples['api']\n",
    "    \n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='np',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "# Path to the directory where the tokenized dataset will be saved or loaded\n",
    "directory_path = 'tokenized_datasets'\n",
    "file_name = 'catak_tokenized'\n",
    "full_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "# Check if the directory and file already exist\n",
    "if os.path.exists(full_path):\n",
    "    # Load the existing dataset\n",
    "    tokenized_dataset = load_from_disk(full_path)\n",
    "    print(\"Loaded the tokenized dataset.\")\n",
    "else:\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Save the new tokenized dataset\n",
    "    tokenized_dataset.save_to_disk(full_path)\n",
    "    print(\"Saved new tokenized dataset.\")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import softmax\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    precision = load_metric(\"precision\")\n",
    "    recall = load_metric(\"recall\")\n",
    "    f1 = load_metric(\"f1\")\n",
    "    acc = load_metric(\"accuracy\")\n",
    "    mcc = load_metric(\"matthews_correlation\")\n",
    "    #auc = load_metric(\"auc\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = precision.compute(predictions=predictions, average = \"macro\", references=labels)[\"precision\"]\n",
    "    recall = recall.compute(predictions=predictions, average = \"macro\", references=labels)[\"recall\"]\n",
    "    f1 = f1.compute(predictions=predictions, average = \"macro\", references=labels)[\"f1\"]\n",
    "    acc = acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    mcc = mcc.compute(predictions=predictions, references=labels)[\"matthews_correlation\"]\n",
    "    auc = roc_auc_score(labels, softmax(logits, axis=1), multi_class='ovo', average='macro')\n",
    "    return {\"precision\": precision, \"recall\": recall, \"acc\": acc, \"mcc\": mcc, \"f1\": f1, \"auc\":auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Using Base Model Performance is not Ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0:\n",
      "  Total memory: 25.393692672 GB\n",
      "  Allocated memory: 24.771476992 GB\n",
      "  Cached memory: 24.771559424 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of GPUs available\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    for i in range(n_gpu):\n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Total memory: {torch.cuda.get_device_properties(i).total_memory / 1e9} GB\")\n",
    "        print(f\"  Allocated memory: {torch.cuda.memory_allocated(i) / 1e9} GB\")\n",
    "        print(f\"  Cached memory: {torch.cuda.memory_reserved(i) / 1e9} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough GPU memory to load the model. Trying to clear cache.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()  # Clear cache first\n",
    "\n",
    "try:\n",
    "    # Your model loading code here\n",
    "    model = model.to('cuda')\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e):\n",
    "        print(\"Not enough GPU memory to load the model. Trying to clear cache.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        # Consider further steps here like reducing model/batch size or moving to CPU\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trojan - Backdoor\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    input = tokenizer.encode(malware_calls.iloc[0]['api'], return_tensors=\"pt\")\n",
    "    input = input.to(torch.device(\"cpu\"))\n",
    "    logits = model(input).logits\n",
    "    prediction = torch.argmax(logits)\n",
    "    print(malware_calls.iloc[0]['class'] + \" - \" + IDX2CAT[prediction.tolist()])\n",
    "except RuntimeError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    torch.cuda.empty_cache()  # Clearing the CUDA cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['q_proj', 'v_proj'] # Only apply LORA to the query and value projections, the paper on LORA suggests that this provides the best results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForSequenceClassification(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (score): Linear(in_features=4096, out_features=8, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEFT Will Only Tune %0.06 of the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,227,072 || all params: 6,611,603,456 || trainable%: 0.06393414287670189\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "batch_size = 2\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_name + \"-Malware-Classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 137.19 MiB is free. Process 3282954 has 23.51 GiB memory in use. Of the allocated memory 23.07 GiB is allocated by PyTorch, and 80.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "try:\n",
    "    # creater trainer object\n",
    "    trainer = Trainer(\n",
    "        model=peft_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    torch.cuda.empty_cache()  # Clearing the CUDA cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_model(\"./\")\n",
    "\n",
    "# If you also want to save the tokenizer associated with the model\n",
    "tokenizer.save_pretrained(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
